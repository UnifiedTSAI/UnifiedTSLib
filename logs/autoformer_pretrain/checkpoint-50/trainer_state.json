{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.006389776357827476,
  "eval_steps": 5.0,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00012779552715654952,
      "grad_norm": 4492.39794921875,
      "learning_rate": 0.0001,
      "loss": 0.7298,
      "step": 1
    },
    {
      "epoch": 0.00025559105431309905,
      "grad_norm": 4077.005859375,
      "learning_rate": 9.99999979851577e-05,
      "loss": 0.2199,
      "step": 2
    },
    {
      "epoch": 0.00038338658146964857,
      "grad_norm": 3907.831787109375,
      "learning_rate": 9.999999194063112e-05,
      "loss": 0.3342,
      "step": 3
    },
    {
      "epoch": 0.0005111821086261981,
      "grad_norm": 4670.494140625,
      "learning_rate": 9.999998186642125e-05,
      "loss": 0.5388,
      "step": 4
    },
    {
      "epoch": 0.0006389776357827476,
      "grad_norm": 3450.90478515625,
      "learning_rate": 9.999996776252969e-05,
      "loss": 0.7054,
      "step": 5
    },
    {
      "epoch": 0.0007667731629392971,
      "grad_norm": 4448.734375,
      "learning_rate": 9.999994962895872e-05,
      "loss": 0.275,
      "step": 6
    },
    {
      "epoch": 0.0008945686900958467,
      "grad_norm": 4641.2666015625,
      "learning_rate": 9.999992746571128e-05,
      "loss": 0.2843,
      "step": 7
    },
    {
      "epoch": 0.0010223642172523962,
      "grad_norm": 3568.785888671875,
      "learning_rate": 9.999990127279093e-05,
      "loss": 0.7609,
      "step": 8
    },
    {
      "epoch": 0.0011501597444089457,
      "grad_norm": 3932.45166015625,
      "learning_rate": 9.999987105020187e-05,
      "loss": 0.6355,
      "step": 9
    },
    {
      "epoch": 0.0012779552715654952,
      "grad_norm": 4588.72265625,
      "learning_rate": 9.999983679794901e-05,
      "loss": 0.6809,
      "step": 10
    },
    {
      "epoch": 0.0014057507987220448,
      "grad_norm": 3818.952880859375,
      "learning_rate": 9.999979851603785e-05,
      "loss": 0.6686,
      "step": 11
    },
    {
      "epoch": 0.0015335463258785943,
      "grad_norm": 4108.49072265625,
      "learning_rate": 9.999975620447457e-05,
      "loss": 0.3578,
      "step": 12
    },
    {
      "epoch": 0.0016613418530351438,
      "grad_norm": 4190.5263671875,
      "learning_rate": 9.999970986326599e-05,
      "loss": 0.4833,
      "step": 13
    },
    {
      "epoch": 0.0017891373801916933,
      "grad_norm": 3977.69677734375,
      "learning_rate": 9.999965949241957e-05,
      "loss": 0.4287,
      "step": 14
    },
    {
      "epoch": 0.0019169329073482429,
      "grad_norm": 4502.986328125,
      "learning_rate": 9.999960509194343e-05,
      "loss": 0.397,
      "step": 15
    },
    {
      "epoch": 0.0020447284345047924,
      "grad_norm": 4288.7529296875,
      "learning_rate": 9.999954666184634e-05,
      "loss": 0.6487,
      "step": 16
    },
    {
      "epoch": 0.0021725239616613417,
      "grad_norm": 3622.8828125,
      "learning_rate": 9.999948420213771e-05,
      "loss": 0.7633,
      "step": 17
    },
    {
      "epoch": 0.0023003194888178914,
      "grad_norm": 4294.630859375,
      "learning_rate": 9.999941771282764e-05,
      "loss": 0.6166,
      "step": 18
    },
    {
      "epoch": 0.0024281150159744407,
      "grad_norm": 4272.24072265625,
      "learning_rate": 9.999934719392682e-05,
      "loss": 0.5725,
      "step": 19
    },
    {
      "epoch": 0.0025559105431309905,
      "grad_norm": 4059.493408203125,
      "learning_rate": 9.999927264544663e-05,
      "loss": 0.4441,
      "step": 20
    },
    {
      "epoch": 0.00268370607028754,
      "grad_norm": 5085.33349609375,
      "learning_rate": 9.999919406739906e-05,
      "loss": 0.3353,
      "step": 21
    },
    {
      "epoch": 0.0028115015974440895,
      "grad_norm": 4456.0859375,
      "learning_rate": 9.999911145979681e-05,
      "loss": 0.6,
      "step": 22
    },
    {
      "epoch": 0.002939297124600639,
      "grad_norm": 3944.57177734375,
      "learning_rate": 9.999902482265317e-05,
      "loss": 0.4368,
      "step": 23
    },
    {
      "epoch": 0.0030670926517571886,
      "grad_norm": 4231.39404296875,
      "learning_rate": 9.999893415598213e-05,
      "loss": 0.7895,
      "step": 24
    },
    {
      "epoch": 0.003194888178913738,
      "grad_norm": 4470.931640625,
      "learning_rate": 9.999883945979826e-05,
      "loss": 0.5422,
      "step": 25
    },
    {
      "epoch": 0.0033226837060702876,
      "grad_norm": 4031.77490234375,
      "learning_rate": 9.999874073411688e-05,
      "loss": 0.3867,
      "step": 26
    },
    {
      "epoch": 0.003450479233226837,
      "grad_norm": 4519.5869140625,
      "learning_rate": 9.999863797895387e-05,
      "loss": 0.2668,
      "step": 27
    },
    {
      "epoch": 0.0035782747603833867,
      "grad_norm": 4424.20556640625,
      "learning_rate": 9.999853119432579e-05,
      "loss": 0.405,
      "step": 28
    },
    {
      "epoch": 0.003706070287539936,
      "grad_norm": 3423.97021484375,
      "learning_rate": 9.999842038024987e-05,
      "loss": 0.404,
      "step": 29
    },
    {
      "epoch": 0.0038338658146964857,
      "grad_norm": 5467.5283203125,
      "learning_rate": 9.999830553674396e-05,
      "loss": 0.3139,
      "step": 30
    },
    {
      "epoch": 0.0039616613418530355,
      "grad_norm": 3971.024658203125,
      "learning_rate": 9.999818666382658e-05,
      "loss": 0.856,
      "step": 31
    },
    {
      "epoch": 0.004089456869009585,
      "grad_norm": 4388.9150390625,
      "learning_rate": 9.999806376151689e-05,
      "loss": 0.9648,
      "step": 32
    },
    {
      "epoch": 0.004217252396166134,
      "grad_norm": 4274.4931640625,
      "learning_rate": 9.999793682983467e-05,
      "loss": 0.407,
      "step": 33
    },
    {
      "epoch": 0.004345047923322683,
      "grad_norm": 4238.3779296875,
      "learning_rate": 9.999780586880043e-05,
      "loss": 1.0211,
      "step": 34
    },
    {
      "epoch": 0.0044728434504792336,
      "grad_norm": 4702.8974609375,
      "learning_rate": 9.999767087843523e-05,
      "loss": 0.8875,
      "step": 35
    },
    {
      "epoch": 0.004600638977635783,
      "grad_norm": 3257.957275390625,
      "learning_rate": 9.999753185876087e-05,
      "loss": 0.3713,
      "step": 36
    },
    {
      "epoch": 0.004728434504792332,
      "grad_norm": 4052.313720703125,
      "learning_rate": 9.999738880979974e-05,
      "loss": 0.4051,
      "step": 37
    },
    {
      "epoch": 0.0048562300319488815,
      "grad_norm": 3997.5634765625,
      "learning_rate": 9.99972417315749e-05,
      "loss": 1.1872,
      "step": 38
    },
    {
      "epoch": 0.004984025559105432,
      "grad_norm": 3792.4892578125,
      "learning_rate": 9.999709062411006e-05,
      "loss": 0.3813,
      "step": 39
    },
    {
      "epoch": 0.005111821086261981,
      "grad_norm": 4786.58349609375,
      "learning_rate": 9.999693548742957e-05,
      "loss": 0.7783,
      "step": 40
    },
    {
      "epoch": 0.00523961661341853,
      "grad_norm": 4314.24169921875,
      "learning_rate": 9.999677632155844e-05,
      "loss": 0.2397,
      "step": 41
    },
    {
      "epoch": 0.00536741214057508,
      "grad_norm": 3758.625732421875,
      "learning_rate": 9.999661312652231e-05,
      "loss": 1.1321,
      "step": 42
    },
    {
      "epoch": 0.00549520766773163,
      "grad_norm": 3946.208984375,
      "learning_rate": 9.999644590234753e-05,
      "loss": 0.567,
      "step": 43
    },
    {
      "epoch": 0.005623003194888179,
      "grad_norm": 4079.698974609375,
      "learning_rate": 9.999627464906099e-05,
      "loss": 0.2074,
      "step": 44
    },
    {
      "epoch": 0.005750798722044728,
      "grad_norm": 4051.353515625,
      "learning_rate": 9.999609936669035e-05,
      "loss": 0.6658,
      "step": 45
    },
    {
      "epoch": 0.005878594249201278,
      "grad_norm": 4279.958984375,
      "learning_rate": 9.999592005526384e-05,
      "loss": 0.4981,
      "step": 46
    },
    {
      "epoch": 0.006006389776357828,
      "grad_norm": 4621.7451171875,
      "learning_rate": 9.999573671481035e-05,
      "loss": 0.387,
      "step": 47
    },
    {
      "epoch": 0.006134185303514377,
      "grad_norm": 3656.33056640625,
      "learning_rate": 9.999554934535947e-05,
      "loss": 0.3199,
      "step": 48
    },
    {
      "epoch": 0.0062619808306709265,
      "grad_norm": 4355.58544921875,
      "learning_rate": 9.999535794694135e-05,
      "loss": 0.9155,
      "step": 49
    },
    {
      "epoch": 0.006389776357827476,
      "grad_norm": 4518.73193359375,
      "learning_rate": 9.999516251958688e-05,
      "loss": 0.5372,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 7825,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 5,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1037548814400.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
